{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIeu53s+EPx2G2pgjlCWoH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amsaghiri/Multi-armed-bandit/blob/main/MABgame2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "KTy92FVMH0V3",
        "outputId": "df3ffdc4-f5eb-4264-d7b4-f2204a473d54"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9a1afa0c268c>\u001b[0m in \u001b[0;36m<cell line: 110>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex_num_iteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mrate_yes_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate_yes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0maction_selected_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mrate_yes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate_yes\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnumber_players\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'rate_yes' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Bandit class represents an individual bandit problem\n",
        "class Bandit:\n",
        "    def __init__(self, n_arms, epsilon, alpha):\n",
        "        self.n_arms = n_arms  # Number of arms (actions)\n",
        "        self.epsilon = epsilon  # Exploration rate\n",
        "        self.alpha = alpha  # Learning rate\n",
        "        self.q = np.zeros(n_arms)  # Action values for each arm initialized to 0\n",
        "        self.actions = []  # List to store selected actions\n",
        "        self.rewards = []  # List to store obtained rewards\n",
        "        self.optimal = []  # List to store whether selected action was optimal\n",
        "\n",
        "    # Epsilon-greedy algorithm for action selection\n",
        "    def epsilon_greedy(self):\n",
        "        if np.random.random() < self.epsilon:\n",
        "            return np.random.randint(self.n_arms)  # Random action selection\n",
        "        else:\n",
        "            return np.argmax(self.q)  # Greedy action selection based on action values\n",
        "\n",
        "    # Update action value based on obtained reward\n",
        "    def update_action_value(self, action, reward):\n",
        "        self.q[action] += self.alpha * (reward - self.q[action])  # Update action value using incremental update\n",
        "        return self.q[action]\n",
        "\n",
        "    # Run the bandit problem for a given number of iterations\n",
        "    def run(self, num_iterations):\n",
        "        self.actions = np.zeros(num_iterations)\n",
        "        self.rewards = np.zeros(num_iterations)\n",
        "        self.optimal = np.zeros(num_iterations)\n",
        "\n",
        "        for t in range(num_iterations):\n",
        "            action = self.epsilon_greedy()\n",
        "            self.actions[t] = action\n",
        "            reward = self.rewards[t]\n",
        "            self.rewards[t] = reward\n",
        "            optimal_action = np.argmax(self.q)\n",
        "            self.optimal[t] = action == optimal_action\n",
        "            self.update_action_value(action, reward)\n",
        "\n",
        "        results = {\n",
        "            'actions': self.actions,\n",
        "            'rewards': self.rewards,\n",
        "            'optimal': self.optimal\n",
        "        }\n",
        "\n",
        "        return results\n",
        "\n",
        "\n",
        "# Node class represents a node in the graph\n",
        "class Node:\n",
        "    def __init__(self, id):\n",
        "        self.id = id  # Node ID\n",
        "        self.bandit = None  # Each node has a bandit instance associated with it\n",
        "\n",
        "\n",
        "# Graph class represents the overall graph structure\n",
        "class Graph:\n",
        "    def __init__(self, nodes):\n",
        "        self.nodes = nodes  # List to store graph nodes\n",
        "\n",
        "    # Add a node to the graph\n",
        "    def add_node(self, node):\n",
        "        self.nodes.append(node)\n",
        "\n",
        "    # Get all nodes in the graph\n",
        "    def get_nodes(self):\n",
        "        return self.nodes\n",
        "\n",
        "\n",
        "# Environment class generates rewards based on a given rate\n",
        "class Environment:\n",
        "    def __init__(self, r):\n",
        "        self.r = r  # Reward value\n",
        "\n",
        "    # Get a reward based on the rate of 'Yes'\n",
        "    def get_reward(self, rate_yes):\n",
        "        if np.random.random() < rate_yes:\n",
        "            return self.r\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "\n",
        "# Setting\n",
        "num_iteration = 100000  # Number of iterations\n",
        "r = 2  # Reward value\n",
        "number_players = 10  # Number of players\n",
        "rate_yes_list = []  # List to store rate of 'Yes' over iterations\n",
        "\n",
        "# Set third action as the favored action!\n",
        "environment = Environment(r)  # Create environment instance\n",
        "graph = Graph([])  # Create graph instance with no nodes\n",
        "\n",
        "# Define rate ranges for each player\n",
        "def probability_players(i):\n",
        "    switcher = {\n",
        "        0: [0.4, 0.6],\n",
        "        1: [0.45, 0.55],\n",
        "        2: [0.1, 0.9],\n",
        "        3: [0.3, 0.7],\n",
        "        4: [0.45, 0.55],\n",
        "        5: [0.35, 0.65],\n",
        "        6: [0.35, 0.65],\n",
        "        7: [0.2, 0.8],\n",
        "        8: [0.5, 0.5],\n",
        "        9: [0.6, 0.4]\n",
        "    }\n",
        "    return switcher.get(i)\n",
        "\n",
        "# Create nodes and associated bandit instances\n",
        "for i in range(number_players):\n",
        "    node = Node(i + 1)\n",
        "    bandit_instance = Bandit(2, 0.1, 0.1)\n",
        "    node.bandit = bandit_instance\n",
        "    graph.add_node(node)\n",
        "\n",
        "# Iterate for each number of iterations\n",
        "for index_num_iteration in range(num_iteration):\n",
        "    rate_yes=0\n",
        "    rate_yes_list.append(rate_yes)\n",
        "    action_selected_list = []\n",
        "    rate_yes = float(rate_yes/number_players)\n",
        "\n",
        "    # Iterate over nodes in the graph\n",
        "    for node in graph.get_nodes():\n",
        "        favor_action = node.bandit.epsilon_greedy()  # Select action using epsilon-greedy algorithm\n",
        "        reward = environment.get_reward(rate_yes)  # Get reward from the environment\n",
        "        node.bandit.rewards.append(reward)  # Add reward to bandit instance\n",
        "        node.bandit.actions.append(favor_action)  # Add selected action to bandit instance\n",
        "        node.bandit.update_action_value(favor_action, reward)  # Update action value in bandit instance\n",
        "        action_selected_list.append(favor_action)\n",
        "\n",
        "    index_num_iteration += 1\n",
        "    rate_yes = float(rate_yes/number_players)\n",
        "    rate_yes_list.append(rate_yes)\n",
        "\n",
        "# Plotting: Plot favor action for each player\n",
        "for node in graph.get_nodes():\n",
        "    plt.plot(range(num_iteration), node.bandit.actions, label=\"Player {}\".format(node.id))\n",
        "\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Favor action\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plotting: Plot rate of 'Yes' over iterations\n",
        "plt.plot(range(num_iteration), rate_yes_list)\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Rate of Yes\")\n",
        "plt.show()\n"
      ]
    }
  ]
}